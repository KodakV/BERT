{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT тренировка англоязычных отзывов",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KodakV/BERT/blob/master/BERT_user_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Определение эмоциональной окраски твитов с помощью BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1sj0ZndGIaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f2c0bf8a-a947-4e10-9b04-41f92dcbe740"
      },
      "source": [
        "import torch\n",
        "gpuid=0\n",
        "if(torch.cuda.is_available()):\n",
        "    print(torch.cuda.get_device_properties(gpuid))\n",
        "    torch.cuda.set_device(gpuid)\n",
        "    device = torch.device(f'cuda:{gpuid}')\n",
        "else:\n",
        "    device = torch.device(f'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15079MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duVSTe2kF-Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04e38d3e-cccd-47c7-afc2-d734a5702ed9"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "a10958b2-28e8-414f-9ad6-3475e2ea1318"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.91)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ok002ceNB8E7",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf680288-a14b-4912-c01e-4bbebba1a18e"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2GSsTDu6bZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63DQJm6F-aB",
        "colab_type": "text"
      },
      "source": [
        "Мы выбрали необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa6L-HYuF-aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "user_reviews=pd.read_csv('/content/labeled.csv')\n",
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oo_KBFL6eBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "69b319aa-a784-45b4-f6fb-9fc99f0843f6"
      },
      "source": [
        "user_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  toxic\n",
              "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
              "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
              "2                          Собаке - собачья смерть\\n    1.0\n",
              "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
              "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egFP5orbF-aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = user_reviews.iloc[:,0].values\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels=[[int(i)] for i in user_reviews.iloc[:,1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTNAUXpsViZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "021fcbaf-66e5-41f6-86cd-894d89cf7596"
      },
      "source": [
        "sentences[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq3ntGcKF-aZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ba77554-80bf-4ca9-9868-4c452695e12c"
      },
      "source": [
        "print(sentences[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Смотри чтоб тебя не выебли, петушок) [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VSmr5xlF-ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K07ilNF-ai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d955bb5-757b-412b-b987-444a016638fc"
      },
      "source": [
        "print(len(train_gt), len(test_gt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10088 4324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "79fec202-dbdb-4b48-8bfa-3cd3dba7d8c1"
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'н', '##у', 'з', '##а', '##в', '##и', '##с', '##и', '##т', 'о', '##т', 'с', '##ф', '##е', '##р', '##ы', 'к', '##о', '##м', '##п', '##ан', '##ии', 'и', 'п', '##р', '##о', '##е', '##к', '##т', '##а', '.', 'в', 'ф', '##и', '##на', '##н', '##с', '##ов', '##о', '##м', 'а', '##и', '##т', '##и', '-', 'э', '##т', '##о', 'н', '##е', 'р', '##е', '##д', '##к', '##о', '##с', '##т', '##ь', '.', 'н', '##о', 'у', 'н', '##и', '##х', 'и', 'у', '##р', '##ов', '##е', '##н', '##ь', ',', 'в', 'с', '##р', '##е', '##д', '##н', '##е', '##м', ',', 'ч', '##у', '##т', '##ь', 'в', '##ы', '##ш', '##е', 'п', '##о', 'п', '##а', '##л', '##а', '##т', '##е', '.', 'п', '##о', '##м', '##н', '##ю', 'с', '##б', '##е', '##р', 'в', 'с', '##в', '##о', '##е', 'в', '##р', '##е', '##м', '##я', 'в', '##о', '##о', '##б', '##щ', '##е', '30', 'о', '##т', 'р', '##ы', '##н', '##ка', ',', 'д', '##ж', '##а', '##в', '##е', '##р', '##а', '##м', 'д', '##а', '##в', '##а', '##л', 'с', '##х', '##о', '##д', '##у', '.', 'х', '##о', '##т', '##я', 'и', 'н', '##а', 'с', '##т', '##а', '##р', '##т', '##а', '##п', '##а', '##х', ',', 'т', '##а', '##ка', '##я', 'з', '##п', 'т', '##о', '##ж', '##е', 'н', '##е', 'т', '##о', 'ч', '##т', '##о', '##б', '##ы', 'к', '##о', '##с', '##м', '##о', '##с', '.', 'к', '##о', '##р', '##е', '##ш', '##ь', 'п', '##р', '##и', '##м', '##е', '##р', '##н', '##о', 'с', '##т', '##о', '##л', '##ь', '##к', '##о', 'д', '##е', '##л', '##а', '##е', '##т', 'п', '##р', '##о', '##с', '##т', '##о', 'с', '##и', '##н', '##ь', '##о', '##р', 'objective', 'c', 'swift', 'д', '##е', '##в', '##о', '##м', 'в', 'с', '##т', '##а', '##р', '##т', '##а', '##п', '##е', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERTу нужно предоставить специальный формат входных данных.\n",
        "\n",
        "\n",
        "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
        "- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n",
        "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n",
        "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cp9BPRd1tMIo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f06f5fae-9850-441e-edb8-1b23fae62372"
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=400,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2005 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2259 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2960 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1975 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2406 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3101 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2162 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2103 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2284 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4278 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2096 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3114 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1713 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2441 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2274 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3182 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4326 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1983 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2198 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFbE-UHvsb7-",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_gt, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw5K2A5Ko1RF",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPGTwywpF-a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x77U2QWiF-bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "fef53cba-a367-4909-d586-55a6893fc480"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GEgLpFVlo1Z-",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BscUwcSLF-bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF5gAU4SF-bP",
        "colab_type": "text"
      },
      "source": [
        "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z6YOrnsF-bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfb0rNt0F-bT",
        "colab_type": "text"
      },
      "source": [
        "Аналогичные модели есть и для других задач:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiGWfkgLF-bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38114df4-674b-4c03-a354-4cdd468692b7"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QxSMw0FrptiL",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "0823a722-0938-47c9-9674-90c37b475764"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Будем сохранять loss во время обучения\n",
        "# и рисовать график в режиме реального времени\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "\n",
        "# Обучение\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "epochs=3\n",
        "for epoch in range(epochs):\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "      # добавляем батч для вычисления на GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Распаковываем данные из dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      \n",
        "      # если не сделать .zero_grad(), градиенты будут накапливаться\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Forward pass\n",
        "      loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "      train_loss_set.append(loss[0].item())  \n",
        "      \n",
        "      # Backward pass\n",
        "      loss[0].backward()\n",
        "      \n",
        "      # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
        "      optimizer.step()\n",
        "\n",
        "      # Обновляем loss\n",
        "      train_loss += loss[0].item()\n",
        "      \n",
        "      # Рисуем график\n",
        "      clear_output(True)\n",
        "      plt.plot(train_loss_set)\n",
        "      plt.title(\"Training loss\")\n",
        "      plt.xlabel(\"Batch\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.show()\n",
        "      \n",
        "  print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss на обучающей выборке: 1.25828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cUXf8b5UJOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f91cca93-5de3-4c73-c8cf-587a9122166e"
      },
      "source": [
        "# Валидация\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)\n",
        "\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на валидационной выборке: 86.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a074j5u8F-bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7dba2da1-310d-4e4e-c94b-73a6c246ebc7"
      },
      "source": [
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на валидационной выборке: 86.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# Оценка качества на отложенной выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "202abb75-a7f2-4134-b27f-fa81ca51807b"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1975 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3433 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3074 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1942 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1806 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6120 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3456 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2893 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2438 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3429 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2400 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3118 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2828 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2421 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2235 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkTuePe0F-bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_gt)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hba10sXR7Xi6",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKZCIaBoF-b3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce6ca5fd-9fff-42a7-8d7e-9907a5e1c13b"
      },
      "source": [
        "acc_score = accuracy_score(test_labels, test_preds)\n",
        "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
        "    acc_score*100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на отложенной выборке составил: 85.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wCmfm-F-b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4642321e-5385-4a46-a684-53a62aa64ef3"
      },
      "source": [
        "print('Неправильных предсказаний: {0}/{1}'.format(\n",
        "    sum(test_labels != test_preds),\n",
        "    len(test_labels)\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-564f4a8b4f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print('Неправильных предсказаний: {0}/{1}'.format(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ))\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPJEzTsEF-b_",
        "colab_type": "text"
      },
      "source": [
        "### Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FowNVSHF-cA",
        "colab_type": "text"
      },
      "source": [
        "Скачайте датасет с отзывами на фильмы. Например, используйте датасет [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ELL_PsF-cJ",
        "colab_type": "text"
      },
      "source": [
        "Используйте для дообучения BERT датасет IMDB. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W2hWjIxF-cK",
        "colab_type": "text"
      },
      "source": [
        "Ответьте на вопросы:\n",
        "1. удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n",
        "2. удалось ли получить хорошее качество классификации всего за одну эпоху?\n",
        "3. подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n",
        "    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n",
        "    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztLDKCG6F-cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_texts = pd.read_csv('/content/positive.csv', encoding='utf8', sep=';', header=None)\n",
        "neg_texts = pd.read_csv('/content/negative.csv', encoding='utf8', sep=';', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izskz92yRlTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrFSdzajP2Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjoEEP8bYrpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0be8af8d-7851-4f68-82db-e98de08dcfa7"
      },
      "source": [
        "print(sentences[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] @jolechka3 получается,осторожно котлетку перекладываю в др.посуду) [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPloJflsZPbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=300,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7epfKax1ZpUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_gt)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7urcXNSZ20L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsEA_irFZ4Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "727b01d4-b70d-4eb8-8a09-8dfba160452f"
      },
      "source": [
        "acc_score = accuracy_score(test_labels, test_preds)\n",
        "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
        "    acc_score*100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на отложенной выборке составил: 46.37%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}