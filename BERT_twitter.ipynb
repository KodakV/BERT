{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_тренировка на твитах",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KodakV/BERT/blob/master/BERT_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Определение эмоциональной окраски твитов с помощью BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1sj0ZndGIaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68b913e7-7ae9-4319-8d20-baea85cecb68"
      },
      "source": [
        "import torch\n",
        "gpuid=0\n",
        "if(torch.cuda.is_available()):\n",
        "    print(torch.cuda.get_device_properties(gpuid))\n",
        "    torch.cuda.set_device(gpuid)\n",
        "    device = torch.device(f'cuda:{gpuid}')\n",
        "else:\n",
        "    device = torch.device(f'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15079MB, multi_processor_count=40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duVSTe2kF-Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbd42a4b-3e33-484d-c02b-5b40aacfda5d"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stepik-dl-nlp'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 273 (delta 3), reused 5 (delta 2), pack-reused 266\u001b[K\n",
            "Receiving objects: 100% (273/273), 42.13 MiB | 19.74 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 1)) (0.22.2.post1)\n",
            "Collecting spacy-udpipe\n",
            "  Downloading https://files.pythonhosted.org/packages/81/ff/878cb73163141ecb34e19b0008cb064cceb4ce6c1070d04d180c6a5d1d10/spacy_udpipe-0.3.1-py3-none-any.whl\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 4)) (1.6.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 5)) (3.2.2)\n",
            "Collecting ipymarkup\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 7)) (4.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 9)) (1.0.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 10)) (4.41.1)\n",
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 12)) (0.10.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 13)) (4.10.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 14)) (5.5.0)\n",
            "Collecting pyconll\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.2.4)\n",
            "Collecting ufal.udpipe>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 21.6MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (0.10.0)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r stepik-dl-nlp/requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome->-r stepik-dl-nlp/requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (49.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.8.0)\n",
            "Requirement already satisfied: requests>=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from intervaltree>=3->ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.1.0)\n",
            "Building wheels for collected packages: ufal.udpipe, intervaltree\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp36-cp36m-linux_x86_64.whl size=5625297 sha256=b5a04801da1fb338f6670b8aa0a9a49cdc950854cfad2ed7e61aa9ca3c0627df\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=b1e2376bb2248231bb4fee3c909753ad11f407fba3bb833c03388fe6b1e17376\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built ufal.udpipe intervaltree\n",
            "Installing collected packages: ufal.udpipe, spacy-udpipe, dawg-python, pymorphy2-dicts, pymorphy2, intervaltree, ipymarkup, youtokentome, pyconll\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 pyconll-2.2.1 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 spacy-udpipe-0.3.1 ufal.udpipe-1.2.0.3 youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "c18d7a66-2b8d-40cc-d58a-651ed334d97a"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 4.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.33)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4531bf739f3bfbf8f58035bf610cec0a8f06bc11b76668a6cd6bed1fc7410aea\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ok002ceNB8E7",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93d50b40-e820-484f-d5ab-c2f776d2d015"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63DQJm6F-aB",
        "colab_type": "text"
      },
      "source": [
        "Мы выбрали необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa6L-HYuF-aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
        "pos_texts = pd.read_csv('/content/positive.csv', encoding='utf8', sep=';', header=None)\n",
        "neg_texts = pd.read_csv('/content/negative.csv', encoding='utf8', sep=';', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "untVmTQfF-aJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "8f3be2ab-e6a8-4557-8b8f-5b1e3748bc79"
      },
      "source": [
        "pos_texts.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98404</th>\n",
              "      <td>411052664009818113</td>\n",
              "      <td>1386837566</td>\n",
              "      <td>FrostCarbe</td>\n",
              "      <td>В город езжу последнее время как в порядке вещ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>551</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10080</th>\n",
              "      <td>409282013049651200</td>\n",
              "      <td>1386415410</td>\n",
              "      <td>hellobadwolf</td>\n",
              "      <td>@tardisarecool действительно)видать,очень даль...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104495</th>\n",
              "      <td>411121618283675648</td>\n",
              "      <td>1386854006</td>\n",
              "      <td>AleksFLawyer</td>\n",
              "      <td>Вот такая вот занимательная статистика) http:/...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>309</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94337</th>\n",
              "      <td>411000144117526528</td>\n",
              "      <td>1386825045</td>\n",
              "      <td>sakhaaias</td>\n",
              "      <td>@iratequilala ахах того аючэ?:) я в е твоя фан...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7082</td>\n",
              "      <td>272</td>\n",
              "      <td>265</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41158</th>\n",
              "      <td>409928039154204672</td>\n",
              "      <td>1386569435</td>\n",
              "      <td>mizotw</td>\n",
              "      <td>RT \"@AniaBelyakova: лень ) http://t.co/AUnkxQM...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23344</td>\n",
              "      <td>2712</td>\n",
              "      <td>203</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        0           1             2   ...    9    10  11\n",
              "98404   411052664009818113  1386837566    FrostCarbe  ...     8   10   0\n",
              "10080   409282013049651200  1386415410  hellobadwolf  ...     1    2   0\n",
              "104495  411121618283675648  1386854006  AleksFLawyer  ...    59   69   0\n",
              "94337   411000144117526528  1386825045     sakhaaias  ...   272  265   1\n",
              "41158   409928039154204672  1386569435        mizotw  ...  2712  203  15\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egFP5orbF-aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n",
        "\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTNAUXpsViZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c5b3a91-818a-46ba-8a27-3fdbf208dc5d"
      },
      "source": [
        "sentences[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJTwflKSF-aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq3ntGcKF-aZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7343a403-4447-45e8-af43-828c2021fa66"
      },
      "source": [
        "print(sentences[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Дим, ты помогаешь мне, я тебе, все взаимно, все правильно) [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VSmr5xlF-ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K07ilNF-ai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb43e545-9ad6-46bd-cb4c-8e48fe41dab2"
      },
      "source": [
        "print(len(train_gt), len(test_gt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "158783 68051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0f9aa51a-dac1-4302-e2e6-0aab7b61fa59"
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 858741.37B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', '@', 'ty', '##uk', '##ovo', '##leg', 'я', 'и', 'н', '##е', 'п', '##е', '##р', '##е', '##ж', '##е', '##в', '##ы', '##в', '##а', '##ю', ')', ')', ')', ',', 'ч', '##е', 'м', '##н', '##е', 'п', '##е', '##р', '##е', '##ж', '##е', '##в', '##ы', '##в', '##а', '##т', '##ь', ')', ')', ')', ')', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERTу нужно предоставить специальный формат входных данных.\n",
        "\n",
        "\n",
        "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
        "- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n",
        "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n",
        "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cp9BPRd1tMIo",
        "colab": {}
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFbE-UHvsb7-",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_gt, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw5K2A5Ko1RF",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPGTwywpF-a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x77U2QWiF-bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "1732f950-c67c-4ad3-bb31-995f12aecaf8"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        ...,\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GEgLpFVlo1Z-",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BscUwcSLF-bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF5gAU4SF-bP",
        "colab_type": "text"
      },
      "source": [
        "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z6YOrnsF-bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfb0rNt0F-bT",
        "colab_type": "text"
      },
      "source": [
        "Аналогичные модели есть и для других задач:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiGWfkgLF-bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0ad8158-01be-4e86-abb8-55ca669758a2"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 115795.31B/s]\n",
            "100%|██████████| 440473133/440473133 [00:13<00:00, 33869909.12B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QxSMw0FrptiL",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "f7963b9b-55bf-4a52-a4af-c12ccbabc3e8"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Будем сохранять loss во время обучения\n",
        "# и рисовать график в режиме реального времени\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "\n",
        "# Обучение\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss[0].item())  \n",
        "    \n",
        "    # Backward pass\n",
        "    loss[0].backward()\n",
        "    \n",
        "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
        "    optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "    train_loss += loss[0].item()\n",
        "    \n",
        "    # Рисуем график\n",
        "    clear_output(True)\n",
        "    plt.plot(train_loss_set)\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f08ce431f2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Обновляем параметры и делаем шаг используя посчитанные градиенты\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cUXf8b5UJOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90e9058d-730f-498e-ea39-d58b8b95e977"
      },
      "source": [
        "# Валидация\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)\n",
        "\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на валидационной выборке: 97.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a074j5u8F-bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d459ad9e-74c1-4656-b392-6e165b89e2d1"
      },
      "source": [
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-af3aaab849a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# Оценка качества на отложенной выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mAN0LZBOOPVh",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkTuePe0F-bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_gt)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hba10sXR7Xi6",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKZCIaBoF-b3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "130ee4ec-55ee-44ef-d637-b8730ca0788c"
      },
      "source": [
        "acc_score = accuracy_score(test_labels, test_preds)\n",
        "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
        "    acc_score*100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на отложенной выборке составил: 97.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wCmfm-F-b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c61cbf3b-af78-4edd-b99c-6ab06a5a0a4a"
      },
      "source": [
        "print('Неправильных предсказаний: {0}/{1}'.format(\n",
        "    sum(test_labels != test_preds),\n",
        "    len(test_labels)\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-564f4a8b4f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print('Неправильных предсказаний: {0}/{1}'.format(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ))\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPJEzTsEF-b_",
        "colab_type": "text"
      },
      "source": [
        "### Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FowNVSHF-cA",
        "colab_type": "text"
      },
      "source": [
        "Скачайте датасет с отзывами на фильмы. Например, используйте датасет [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ELL_PsF-cJ",
        "colab_type": "text"
      },
      "source": [
        "Используйте для дообучения BERT датасет IMDB. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W2hWjIxF-cK",
        "colab_type": "text"
      },
      "source": [
        "Ответьте на вопросы:\n",
        "1. удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n",
        "2. удалось ли получить хорошее качество классификации всего за одну эпоху?\n",
        "3. подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n",
        "    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n",
        "    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztLDKCG6F-cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izskz92yRlTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_reviews=pd.read_csv('/content/df_user_reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaIfzY7NR-QW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "92c0e1d6-d12a-4ebf-f131-89255344b9a5"
      },
      "source": [
        "user_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Translated_Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This help eating healthy exercise regular basis</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Works great especially going grocery store</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Best idea us</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Best way</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                  Translated_Review  Sentiment\n",
              "0           0  I like eat delicious food. That's I'm cooking ...        1.0\n",
              "1           1    This help eating healthy exercise regular basis        1.0\n",
              "2           3         Works great especially going grocery store        1.0\n",
              "3           4                                       Best idea us        1.0\n",
              "4           5                                           Best way        1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpJ-39cxXRLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "80ff72cb-b453-49c2-8e00-3aaa8df6e4f5"
      },
      "source": [
        "user_reviews.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0             int64\n",
              "Translated_Review     object\n",
              "Sentiment            float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gxTTAcWXFm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = user_reviews.Translated_Review.values\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels=[[int(i)] for i in user_reviews.Sentiment]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjoEEP8bYrpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31f481e3-79ea-43cd-c65b-adabe8751323"
      },
      "source": [
        "print(sentences[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] One greatest apps. [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPloJflsZPbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "aa6c5817-5f4a-4dd0-d4e6-49e565bf12db"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=300,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7epfKax1ZpUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7urcXNSZ20L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsEA_irFZ4Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2ac5af1-1a1c-480c-bdf6-1ce293a50aec"
      },
      "source": [
        "acc_score = accuracy_score(test_labels, test_preds)\n",
        "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
        "    acc_score*100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на отложенной выборке составил: 31.92%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}